from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from bs4 import BeautifulSoup

existing_dict = {
    '1 - Downloaded file lists\n2 - Start download - small file\n3 - Start download - large file\nPause - Pause download\nPlay - Resume download\nStop - Cancel download\n0 - Clear logs': '<ix:nonnumeric context="c1" continuedat="cont1" escape="false" id="f1" name="eg:DescriptionOfPolicy">',
    'Info\nThis application demonstrates the usage of Tizen download API\nThe application downloads files from\nhttp://techslides.com\nand\nhttp://download.blender.org\n. If these domains are not accessible it will not work.\nInfo\nYou can change the source location of files to download\nby changing the contents of\nurl1\nand\nurl2\nvariables in\nmain.js\nfile': '<ix:nonnumeric context="c1" continuedat="cont1" escape="false" id="f1" name="eg:DescriptionOfPolicy">',
    'Info\nYou can change the source location of files to download': '<ix:nonnumeric context="c1" continuedat="cont1" escape="false" id="f1" name="eg:sample">'
}

# Function to calculate cosine similarity
def calculate_similarity(text1, text2):
    vectorizer = CountVectorizer().fit_transform([text1, text2])
    vectors = vectorizer.toarray()
    return cosine_similarity(vectors)[0, 1]

# Function to tag text based on contextual similarity
def tag_text(html_content, existing_dict):
    soup = BeautifulSoup(html_content, 'html.parser')
    for tag in soup.find_all(text=True):
        for key, value in existing_dict.items():
            similarity = calculate_similarity(tag, key)
            if similarity >= 0.9:
                tag.replace_with(f'{value}{tag}{value}')
    return soup.prettify()

# Example usage
html_content = """
<html>
<body>
<p>1 - Downloaded file lists</p>
<p>Info</p>
<p>This application demonstrates the usage of Tizen download API</p>
</body>
</html>
"""

tagged_content = tag_text(html_content, existing_dict)
print(tagged_content)



from bs4 import BeautifulSoup

html_content = """
<html>
<body>
<p>1 - Downloaded file lists</p>
<p>Info</p>
<p>This application demonstrates the usage of Tizen download API</p>
</body>
</html>
"""

# Parse the HTML content
soup = BeautifulSoup(html_content, 'html.parser')

# Define the text content and attributes for the ix:nonNumeric tag
text_to_tag = "This application demonstrates the usage of Tizen download API"
attributes = {'some_attribute': 'some_value', 'another_attribute': 'another_value'}

# Find the paragraph containing the text to tag
paragraph_to_tag = soup.find('p', text=text_to_tag)

# Create the new ix:nonNumeric tag
tag = soup.new_tag('ix:nonNumeric', **attributes)
tag.string = text_to_tag

# Replace the paragraph containing the text with the new ix:nonNumeric tag
paragraph_to_tag.replace_with(tag)

# Print the modified HTML content
print(soup.prettify())







# Sample dictionary
sentence_dict = {
    "key1": "This is a sample sentence for testing purposes",
    "key2": "Another example sentence to demonstrate the process"
}

# Sample list of strings
sentence_list = [
    "This is a different sentence that doesn't match the dictionary",
    "A sample sentence for testing purposes",
    "Another example sentence to demonstrate something else"
]

# Extract first five and last five words from each key's string value
extracted_parts = {key: {'first': value.split()[:5], 'last': value.split()[-5:]} for key, value in sentence_dict.items()}

# Fetch the whole sentences from the list based on the extracted parts
matching_sentences = {key: [sentence for sentence in sentence_list if extracted_parts[key]['first'] == sentence.split()[:5] and extracted_parts[key]['last'] == sentence.split()[-5:]] for key in extracted_parts}

print(matching_sentences)






from bs4 import BeautifulSoup
import re
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Function to extract text content from HTML document
def extract_text_from_html(html_content):
    soup = BeautifulSoup(html_content, 'html.parser')
    text = ' '.join([tag.get_text() for tag in soup.find_all()])
    return text

# Function to preprocess text
def preprocess_text(text):
    # Remove non-alphanumeric characters
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)
    # Convert to lowercase
    text = text.lower()
    return text

# Function to compare two HTML documents based on text content
def compare_html_documents(html_doc1, html_doc2):
    # Extract text content from HTML documents
    text1 = extract_text_from_html(html_doc1)
    text2 = extract_text_from_html(html_doc2)

    # Preprocess text
    text1 = preprocess_text(text1)
    text2 = preprocess_text(text2)

    # Calculate cosine similarity
    vectorizer = CountVectorizer().fit_transform([text1, text2])
    similarity = cosine_similarity(vectorizer)[0, 1]

    return similarity

# Sample HTML documents
html_doc1 = """
<html>
<head><title>Document 1</title></head>
<body>
<p>This is document 1.</p>
</body>
</html>
"""

html_doc2 = """
<html>
<head><title>Document 2</title></head>
<body>
<p>This is document 2.</p>
</body>
</html>
"""

# Compare the two HTML documents
similarity_score = compare_html_documents(html_doc1, html_doc2)
print("Similarity score:", similarity_score)






from bs4 import BeautifulSoup

# Example HTML contents
html_content1 = """
<c>
<div><p>Text 1</p></div>
<div><p>Text 2</p></div>
</c>
"""
html_content2 = """
<div><p>Text 2</p></div>
<div><p>Text 1</p></div>
"""

# Parse HTML contents
soup1 = BeautifulSoup(html_content1, "html.parser")
soup2 = BeautifulSoup(html_content2, "html.parser")

# Find the custom <c> tag in soup1
custom_tag = soup1.find("c")

# Iterate over tags in both contents
for tag1, tag2 in zip(custom_tag.find_all(), soup2.find_all()):
    # Compare tags
    if tag1.name == tag2.name:
        # Replace tag in soup2 with custom tag if they are similar
        tag2.replace_with(soup2.new_tag("c", text=tag2.text))

# Print modified content
print(soup2.prettify())










all_tags = soup.find_all(True)

# Initialize variables
sections = []
current_section = []
tag6_found = False

for tag in all_tags:
    if not tag6_found and tag.name == 'c' and tag.get('tag_id') == '6':
        tag6_found = True
    elif tag6_found:
        if tag.name == 'c' and tag.get('tag_id') == '67':
            sections.append(current_section)
            current_section = []
            tag6_found = False
        else:
            current_section.append(tag)

# sections will contain a list of lists, where each inner list contains tags between <C tag_id=6> and <C tag_id=67>



all_tags = soup.find_all(True)

# Initialize variables
tag6_found = False
tag67_found = False
tags_between = []

for tag in all_tags:
    if not tag6_found and tag.name == 'c' and tag.get('tag_id') == '6':
        tag6_found = True
    elif tag6_found and not tag67_found:
        tags_between.append(tag)
        if tag.name == 'c' and tag.get('tag_id') == '67':
            tag67_found = True
            break

# tags_between will contain all tags between <C tag_id=6> and <C tag_id=67>

